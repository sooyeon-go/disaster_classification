{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from torchtext import data\n",
    "from torchtext.data import TabularDataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 초기 설정\n",
    "\n",
    "## 1) seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f265c05be70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 5\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "TRAIN_SIZE = 0.7\n",
    "# model\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 30\n",
    "DROP_RATE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu와 cuda 중 다음 기기로 학습함: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA\n",
    "\n",
    "## 0) get DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1> set several paths\n",
    "PATH_TRAIN = '../input/nlp-getting-started/train.csv'\n",
    "PATH_TEST = '../input/nlp-getting-started/test.csv'\n",
    "\n",
    "### 2> read_csv\n",
    "df_train = pd.read_csv(PATH_TRAIN)\n",
    "df_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocess (Cleaning) \n",
    "\n",
    "\n",
    "## 0) concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "(3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train.append(df_test, sort=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Cleaning by Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    \n",
    "    return url.sub('', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    \n",
    "    return html.sub('', text)\n",
    "    \n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: remove_URL(x))\n",
    "df['text'] = df['text'].apply(lambda x: remove_html(x))\n",
    "df['text'] = df['text'].apply(lambda x: remove_emoji(x))\n",
    "df['text'] = df['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Lemmatization (표제어 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = df_train.keyword.unique()[1:]\n",
    "keywords = list(map(lambda x: x.replace('%20', ' '), keywords))\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    sentence_words = sentence.split(' ')\n",
    "    new_sentence_words = list()\n",
    "    \n",
    "    for sentence_word in sentence_words:\n",
    "        sentence_word = sentence_word.replace('#', '')\n",
    "        new_sentence_word = wnl.lemmatize(sentence_word.lower(), wordnet.VERB)\n",
    "        new_sentence_words.append(new_sentence_word)\n",
    "        \n",
    "    new_sentence = ' '.join(new_sentence_words)\n",
    "    new_sentence = new_sentence.strip()\n",
    "    \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: lemmatize_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Pytorch\n",
    "-------\n",
    "\n",
    "# 3. Data Preprocess\n",
    "\n",
    "## 1) prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:len(df_train)]\n",
    "df_test = df.iloc[len(df_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['id','text','target']]\n",
    "df_test = df_test[['id','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('preprocessed_train.csv'):\n",
    "    df_train.to_csv('preprocessed_train.csv', index = False)\n",
    "    \n",
    "if not os.path.exists('preprocessed_test.csv'):\n",
    "    df_test.to_csv('preprocessed_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## 2) Field 정의하기\n",
    "\n",
    "### 1> Field란?\n",
    "\n",
    "- datatype을 define: TEXT와 LABEL 객체를 정의해준다. (input과 output을 정의해준다.)\n",
    "- 추후 어떤 전처리를 할 것인지 정의한다.\n",
    "\n",
    "(data를 받을 객체를 미리 선언하는 것 같다.)\n",
    "\n",
    "### 2> 내부 기능\n",
    "\n",
    "- sequential: 해당 data가 sequential data인지 여부 (default는 True)\n",
    "- use_vocab: 단어 집합을 만들 것인가 여부\n",
    "    - 단어 집합: 중복을 제거한 텍스트의 총 단어의 집합(set)\n",
    "- tokenize: 어떤 token화 함수를 사용할 것인지 지정 (default는 string.split)\n",
    "- lower : 영어 데이터를 전부 소문자화한다. (default는 False)\n",
    "    - 컴퓨터는 대문자와 소문자를 다르게 판단하므로 필요한 기능\n",
    "- batch_first : 미니 배치 차원을 맨 앞으로 하여 데이터를 불러올 것인지 여부. (default는 False)\n",
    "- is_target : 레이블 데이터 여부. (default는 False)\n",
    "- fix_length : 최대 허용 길이. 이 길이에 맞춰서 패딩 작업(Padding)이 진행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(sequential=True, \n",
    "                            tokenize='spacy', \n",
    "                            lower=True, \n",
    "                            include_lengths=True, \n",
    "                            batch_first=True, \n",
    "                            fix_length=25)\n",
    "LABEL = torchtext.data.Field(use_vocab=True,\n",
    "                           sequential=False,\n",
    "                           dtype=torch.float16)\n",
    "ID = torchtext.data.Field(use_vocab=False,\n",
    "                         sequential=False,\n",
    "                         dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## 3) CSV -> TabularDataset\n",
    "\n",
    "### 1> TabularDataset\n",
    "\n",
    "- 데이터를 불러오면서 \n",
    "- 필드에서 정의했던 토큰화 방법으로 토큰화를 수행합니다 (이때, 소문자화 같은 기본적인 전처리도 함께 이루어집니다.)\n",
    "\n",
    "### 2> 내부 기능\n",
    "\n",
    "- path : 파일이 위치한 경로.\n",
    "- format : 데이터의 포맷.\n",
    "- fields : 위에서 정의한 필드를 지정. 첫번째 원소는 데이터 셋 내에서 해당 필드를 호칭할 이름, 두번째 원소는 지정할 필드.\n",
    "<font color = 'red'> (DataFrame은 column 순서대로 field 지정해야 한다.) </font>\n",
    "- skip_header : 데이터의 첫번째 줄은 무시. <font color = 'red'> 꼭 해야한다. 안 그러면 column이 data로 끼어든다. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TabularDataset(path='preprocessed_train.csv', format='csv', skip_header=True,\n",
    "                            fields=[('id', ID), ('text', TEXT), ('target', LABEL)])\n",
    "testset = TabularDataset(path='preprocessed_test.csv', format='csv', skip_header=True,\n",
    "                            fields=[('id', ID), ('text', TEXT)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## 4) 단어 집합(단어장, vocabulary) 생성\n",
    "\n",
    "### 1> 단어 집합이란?\n",
    "\n",
    "- 중복을 제거한 총 단어들의 집합\n",
    "- 단어 집합으로 추후 어떤 기준을 가지고(몇 번 등장?, 등장 순위별) 정수 인코딩을 만듭니다.\n",
    "\n",
    "### 2> 내부 기능\n",
    "\n",
    "- min_freq: 단어 집합에 추가 시 단어의 최소 등장 빈도 조건을 추가\n",
    "- max_size: 단어 집합의 최대 크기를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors, GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                           \n",
      "100%|█████████▉| 399480/400000 [00:57<00:00, 7280.59it/s]"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(trainset, testset, \n",
    "                 max_size=20000, min_freq=10,\n",
    "                 vectors=GloVe(name='6B', dim=300))  # We use it for getting vocabulary of words\n",
    "LABEL.build_vocab(trainset)\n",
    "ID.build_vocab(trainset, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## 5) split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = trainset.split(split_ratio = TRAIN_SIZE, random_state=random.getstate(),\n",
    "                                  strata_field = 'target', stratified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "## 6) Build the Iterator(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.Iterator(dataset = trainset, batch_size = BATCH_SIZE, device = DEVICE,\n",
    "                                     train=True, shuffle=True, repeat=False, sort = False)\n",
    "val_iter = torchtext.data.Iterator(dataset = valset, batch_size = BATCH_SIZE, device = DEVICE,\n",
    "                                  train=True, shuffle=True, repeat=False)\n",
    "test_iter = torchtext.data.Iterator(dataset = testset, batch_size = BATCH_SIZE, device = DEVICE,\n",
    "                                   train=False, shuffle=False, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## 7) and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = TEXT.vocab.vectors\n",
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "---------\n",
    "\n",
    "# 4. Build the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embedding_dim, n_classes, dropout_p = DROP_RATE):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [64, 27]\n",
    "        x = self.embed(x)\n",
    "        # x = [64, 27, 128]\n",
    "        h_0 = self._init_state(batch_size = x.size(0))#첫 번째 은닉 벡터 정의\n",
    "        # h_0 = [1, 64, 256]\n",
    "        x, _ = self.lstm(x,(h_0,h_0))\n",
    "        # x = [64, 27, 256]\n",
    "        h_t = x[:,-1,:]\n",
    "        # h_t = [64, 256]\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)\n",
    "        # logit = [64, 2]\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size = 1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    acc, total_loss = 0, 0\n",
    "    for b,batch in enumerate(train_iter):\n",
    "        x, y = batch.text[0], batch.target\n",
    "        y.sub_(1)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.data.to(DEVICE)\n",
    "        optimizer.zero_grad()# 기울기 0으로 초기화\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction = 'mean')\n",
    "        total_loss += loss.item()\n",
    "        acc += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    size = len(train_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100. * acc / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    acc, total_loss = 0., 0.\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text[0], batch.target\n",
    "        y.sub_(1)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.data.to(DEVICE)\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction = 'sum')#오차의 합 구하고 total_loss에 더해줌\n",
    "        total_loss += loss.item()\n",
    "        acc += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100. * acc / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_model(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61bce1cf3ca4f28b37c12519ef90c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<e : 1>> <<train_loss : 0.010890>> <<train_accuracy : 56.089321>> <<val_loss : 0.681105>> <<val_accuracy : 57.049034>>\n",
      "<<e : 2>> <<train_loss : 0.010701>> <<train_accuracy : 57.027584>> <<val_loss : 0.680417>> <<val_accuracy : 57.049034>>\n",
      "<<e : 3>> <<train_loss : 0.010541>> <<train_accuracy : 57.759426>> <<val_loss : 0.660413>> <<val_accuracy : 62.390541>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399480/400000 [01:10<00:00, 7280.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<e : 4>> <<train_loss : 0.008972>> <<train_accuracy : 71.720772>> <<val_loss : 0.549946>> <<val_accuracy : 74.080559>>\n",
      "<<e : 5>> <<train_loss : 0.006856>> <<train_accuracy : 80.709328>> <<val_loss : 0.508388>> <<val_accuracy : 76.882660>>\n",
      "<<e : 6>> <<train_loss : 0.005719>> <<train_accuracy : 84.969032>> <<val_loss : 0.517359>> <<val_accuracy : 78.283714>>\n",
      "<<e : 7>> <<train_loss : 0.004818>> <<train_accuracy : 88.046532>> <<val_loss : 0.594362>> <<val_accuracy : 77.101578>>\n",
      "<<e : 8>> <<train_loss : 0.004057>> <<train_accuracy : 90.898849>> <<val_loss : 0.576452>> <<val_accuracy : 78.064796>>\n",
      "<<e : 9>> <<train_loss : 0.003220>> <<train_accuracy : 92.944267>> <<val_loss : 0.750275>> <<val_accuracy : 73.992996>>\n",
      "<<e : 10>> <<train_loss : 0.002612>> <<train_accuracy : 94.539307>> <<val_loss : 0.695445>> <<val_accuracy : 75.525391>>\n",
      "<<e : 11>> <<train_loss : 0.002214>> <<train_accuracy : 94.970909>> <<val_loss : 0.850475>> <<val_accuracy : 76.576180>>\n",
      "<<e : 12>> <<train_loss : 0.001730>> <<train_accuracy : 95.834114>> <<val_loss : 0.871238>> <<val_accuracy : 76.532394>>\n",
      "<<e : 13>> <<train_loss : 0.001392>> <<train_accuracy : 96.809906>> <<val_loss : 1.040919>> <<val_accuracy : 75.569176>>\n",
      "<<e : 14>> <<train_loss : 0.001303>> <<train_accuracy : 96.659782>> <<val_loss : 0.951236>> <<val_accuracy : 75.700523>>\n",
      "<<e : 15>> <<train_loss : 0.001110>> <<train_accuracy : 97.222740>> <<val_loss : 1.033370>> <<val_accuracy : 77.014008>>\n",
      "<<e : 16>> <<train_loss : 0.001074>> <<train_accuracy : 97.279037>> <<val_loss : 1.014784>> <<val_accuracy : 74.168121>>\n",
      "<<e : 17>> <<train_loss : 0.000977>> <<train_accuracy : 97.485451>> <<val_loss : 1.072160>> <<val_accuracy : 75.744308>>\n",
      "<<e : 18>> <<train_loss : 0.000769>> <<train_accuracy : 97.917053>> <<val_loss : 1.171911>> <<val_accuracy : 76.401047>>\n",
      "<<e : 19>> <<train_loss : 0.000671>> <<train_accuracy : 97.992119>> <<val_loss : 1.435075>> <<val_accuracy : 76.532394>>\n",
      "<<e : 20>> <<train_loss : 0.000613>> <<train_accuracy : 97.973351>> <<val_loss : 1.282088>> <<val_accuracy : 75.306480>>\n",
      "<<e : 21>> <<train_loss : 0.000544>> <<train_accuracy : 98.273598>> <<val_loss : 1.602788>> <<val_accuracy : 75.218910>>\n",
      "<<e : 22>> <<train_loss : 0.000507>> <<train_accuracy : 98.198532>> <<val_loss : 1.606025>> <<val_accuracy : 76.357269>>\n",
      "<<e : 23>> <<train_loss : 0.000524>> <<train_accuracy : 98.273598>> <<val_loss : 1.509813>> <<val_accuracy : 75.394043>>\n",
      "<<e : 24>> <<train_loss : 0.000558>> <<train_accuracy : 98.217300>> <<val_loss : 1.514657>> <<val_accuracy : 76.182137>>\n",
      "<<e : 25>> <<train_loss : 0.000669>> <<train_accuracy : 98.067177>> <<val_loss : 1.256779>> <<val_accuracy : 74.649734>>\n",
      "<<e : 26>> <<train_loss : 0.000830>> <<train_accuracy : 97.673103>> <<val_loss : 1.112539>> <<val_accuracy : 74.562172>>\n",
      "<<e : 27>> <<train_loss : 0.000879>> <<train_accuracy : 97.748169>> <<val_loss : 1.343126>> <<val_accuracy : 74.562172>>\n",
      "<<e : 28>> <<train_loss : 0.000614>> <<train_accuracy : 98.273598>> <<val_loss : 1.388166>> <<val_accuracy : 75.612961>>\n",
      "<<e : 29>> <<train_loss : 0.000543>> <<train_accuracy : 98.179771>> <<val_loss : 1.501872>> <<val_accuracy : 76.138351>>\n",
      "<<e : 30>> <<train_loss : 0.000521>> <<train_accuracy : 98.386185>> <<val_loss : 1.588776>> <<val_accuracy : 75.175133>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in tqdm(range(1, EPOCHS + 1)):\n",
    "    train_loss, train_accuracy = train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"<<e : %d>> <<train_loss : %f>> <<train_accuracy : %f>> <<val_loss : %f>> <<val_accuracy : %f>>\"%(e, train_loss, train_accuracy, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1187a7438b2d456c9ed977ab50faecbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f5787ed43274ea490092cad98b84795": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7e3348679c8a4e1ea46bd6ff43f015e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "927869ab9ac24a84a72b107ebb09aef4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1187a7438b2d456c9ed977ab50faecbd",
       "placeholder": "​",
       "style": "IPY_MODEL_4f5787ed43274ea490092cad98b84795",
       "value": " 30/30 [00:17&lt;00:00,  1.75it/s]"
      }
     },
     "979cacfb7d5d4017bc23a50fc1c1341e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c8ef1d399b504ccba39f303cb1e0087a",
       "max": 30,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d1300ce4f3c84c1e95d20a70543fe9ff",
       "value": 30
      }
     },
     "c8ef1d399b504ccba39f303cb1e0087a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1300ce4f3c84c1e95d20a70543fe9ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d61bce1cf3ca4f28b37c12519ef90c4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_979cacfb7d5d4017bc23a50fc1c1341e",
        "IPY_MODEL_927869ab9ac24a84a72b107ebb09aef4"
       ],
       "layout": "IPY_MODEL_7e3348679c8a4e1ea46bd6ff43f015e6"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
