{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from torchtext import data\n",
    "from torchtext.data import TabularDataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = train[['text','target']]\n",
    "t_chart = test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(text):\n",
    "    text = text.str.lower()\n",
    "    text = text.str.replace('http\\S+','')# http://와 https:// 두 가지 버전 있음\n",
    "    text = text.str.replace('[0-9]','')# 사람 숫자, 날짜\n",
    "    text = text.str.replace('@\\S+','')# '@' 뒤에는 아이디 태그\n",
    "    text = text.str.replace(',','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "chart[\"text\"] = remove(chart[\"text\"])\n",
    "t_chart[\"text\"] = remove(t_chart[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.to_csv('train_r.csv',index = False)\n",
    "t_chart.to_csv('test_r.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('train_r.csv').target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv('train_r.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV -> trainset (= TabularDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "epochs = 20\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential = True, tokenize = str.split, batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TabularDataset(path = 'train_r.csv', format='csv', fields=[('text', TEXT), ('label', LABEL)])\n",
    "testset = TabularDataset(path = 'test_r.csv', format='csv', fields=[('text', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['text'], 'target')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.examples[0].text, trainset.examples[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x23c850c7488>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.examples.pop(0) # column을 제거해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['our',\n",
       "  'deeds',\n",
       "  'are',\n",
       "  'the',\n",
       "  'reason',\n",
       "  'of',\n",
       "  'this',\n",
       "  '#earthquake',\n",
       "  'may',\n",
       "  'allah',\n",
       "  'forgive',\n",
       "  'us',\n",
       "  'all'],\n",
       " '1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.examples[0].text, trainset.examples[0].label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainset -> train_iter (= torchtext.data.Iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainset, min_freq = 2)# 최소 2번 이상 등장한 단어만 사전에 담음\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = trainset.split(split_ratio = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.Iterator(dataset = trainset, batch_size = BATCH_SIZE, device = DEVICE)\n",
    "val_iter = data.Iterator(dataset = valset, batch_size = BATCH_SIZE, device = DEVICE)\n",
    "test_iter = data.Iterator(dataset = testset, batch_size = BATCH_SIZE, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embedding_dim, n_classes, dropout_p = 0.5):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [64, 27]\n",
    "        x = self.embed(x)\n",
    "        # x = [64, 27, 128]\n",
    "        h_0 = self._init_state(batch_size = x.size(0))#첫 번째 은닉 벡터 정의\n",
    "        # h_0 = [1, 64, 256]\n",
    "        x, _ = self.lstm(x,(h_0,h_0))\n",
    "        # x = [64, 27, 256]\n",
    "        h_t = x[:,-1,:]\n",
    "        # h_t = [64, 256]\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)\n",
    "        # logit = [64, 2]\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size = 1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    acc, total_loss = 0, 0\n",
    "    for b,batch in tqdm(enumerate(train_iter)):\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        optimizer.zero_grad()# 기울기 0으로 초기화\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction = 'mean')\n",
    "        total_loss += loss.item()\n",
    "        acc += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    size = len(train_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100 * acc / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    acc, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction = 'sum')#오차의 합 구하고 total_loss에 더해줌\n",
    "        total_loss += loss.item()\n",
    "        acc += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100 * acc / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_model(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  4.75it/s]\n",
      "2it [00:00,  4.60it/s]\n",
      "3it [00:00,  4.63it/s]\n",
      "4it [00:00,  4.68it/s]\n",
      "5it [00:01,  4.59it/s]\n",
      "6it [00:01,  4.76it/s]\n",
      "7it [00:01,  4.78it/s]\n",
      "8it [00:01,  4.55it/s]\n",
      "9it [00:01,  4.72it/s]\n",
      "10it [00:02,  4.83it/s]\n",
      "11it [00:02,  4.93it/s]\n",
      "12it [00:02,  4.76it/s]\n",
      "13it [00:02,  4.75it/s]\n",
      "14it [00:02,  4.57it/s]\n",
      "15it [00:03,  4.49it/s]\n",
      "16it [00:03,  4.58it/s]\n",
      "17it [00:03,  4.84it/s]\n",
      "18it [00:03,  4.82it/s]\n",
      "19it [00:04,  4.87it/s]\n",
      "20it [00:04,  4.77it/s]\n",
      "21it [00:04,  4.74it/s]\n",
      "22it [00:04,  4.83it/s]\n",
      "23it [00:04,  4.80it/s]\n",
      "24it [00:05,  4.52it/s]\n",
      "25it [00:05,  4.39it/s]\n",
      "26it [00:05,  4.53it/s]\n",
      "27it [00:05,  4.62it/s]\n",
      "28it [00:06,  3.58it/s]\n",
      "29it [00:06,  3.88it/s]\n",
      "30it [00:06,  4.08it/s]\n",
      "31it [00:06,  4.28it/s]\n",
      "32it [00:07,  4.48it/s]\n",
      "33it [00:07,  4.45it/s]\n",
      "34it [00:07,  4.55it/s]\n",
      "35it [00:07,  4.57it/s]\n",
      "36it [00:07,  4.53it/s]\n",
      "37it [00:08,  4.62it/s]\n",
      "38it [00:08,  4.75it/s]\n",
      "39it [00:08,  4.77it/s]\n",
      "40it [00:08,  4.80it/s]\n",
      "41it [00:08,  4.49it/s]\n",
      "42it [00:09,  4.30it/s]\n",
      "43it [00:09,  4.44it/s]\n",
      "44it [00:09,  4.37it/s]\n",
      "45it [00:09,  4.51it/s]\n",
      "46it [00:10,  4.60it/s]\n",
      "47it [00:10,  4.77it/s]\n",
      "48it [00:10,  4.65it/s]\n",
      "49it [00:10,  4.56it/s]\n",
      "50it [00:10,  4.60it/s]\n",
      "51it [00:11,  4.73it/s]\n",
      "52it [00:11,  4.84it/s]\n",
      "53it [00:11,  4.93it/s]\n",
      "54it [00:11,  4.80it/s]\n",
      "55it [00:12,  4.60it/s]\n",
      "56it [00:12,  4.45it/s]\n",
      "57it [00:12,  4.51it/s]\n",
      "58it [00:12,  4.58it/s]\n",
      "59it [00:12,  4.73it/s]\n",
      "60it [00:13,  4.17it/s]\n",
      "61it [00:13,  4.37it/s]\n",
      "62it [00:13,  4.43it/s]\n",
      "63it [00:13,  4.49it/s]\n",
      "64it [00:14,  4.49it/s]\n",
      "65it [00:14,  4.69it/s]\n",
      "66it [00:14,  4.51it/s]\n",
      "67it [00:14,  4.18it/s]\n",
      "68it [00:14,  4.25it/s]\n",
      "69it [00:15,  4.34it/s]\n",
      "70it [00:15,  4.48it/s]\n",
      "71it [00:15,  4.48it/s]\n",
      "72it [00:15,  4.43it/s]\n",
      "73it [00:16,  4.54it/s]\n",
      "74it [00:16,  4.15it/s]\n",
      "75it [00:16,  4.28it/s]\n",
      "76it [00:16,  4.60it/s]\n",
      "77it [00:16,  4.60it/s]\n",
      "78it [00:17,  4.73it/s]\n",
      "79it [00:17,  4.86it/s]\n",
      "80it [00:17,  4.95it/s]\n",
      "81it [00:17,  4.96it/s]\n",
      "82it [00:17,  5.02it/s]\n",
      "83it [00:18,  5.05it/s]\n",
      "84it [00:18,  5.06it/s]\n",
      "85it [00:18,  5.06it/s]\n",
      "86it [00:18,  4.92it/s]\n",
      "87it [00:18,  4.75it/s]\n",
      "88it [00:19,  4.85it/s]\n",
      "89it [00:19,  4.86it/s]\n",
      "90it [00:19,  4.89it/s]\n",
      "91it [00:19,  4.87it/s]\n",
      "92it [00:19,  4.80it/s]\n",
      "93it [00:20,  4.79it/s]\n",
      "94it [00:20,  4.81it/s]\n",
      "95it [00:20,  4.85it/s]\n",
      "96it [00:20,  4.90it/s]\n",
      "97it [00:21,  4.94it/s]\n",
      "98it [00:21,  4.91it/s]\n",
      "99it [00:21,  4.83it/s]\n",
      "100it [00:21,  4.81it/s]\n",
      "101it [00:21,  4.91it/s]\n",
      "102it [00:22,  4.88it/s]\n",
      "103it [00:22,  4.76it/s]\n",
      "104it [00:22,  4.90it/s]\n",
      "105it [00:22,  4.63it/s]\n",
      "106it [00:22,  4.33it/s]\n",
      "108it [00:23,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<e : 1>> <<train_loss :  0.01>> <<train_accuracy : 56.00>> <<val_loss :  0.68>> <<val_accuracy : 57.00>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:23<07:35, 23.95s/it]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  4.94it/s]\n",
      "2it [00:00,  4.86it/s]\n",
      "3it [00:00,  4.88it/s]\n",
      "4it [00:00,  4.91it/s]\n",
      "5it [00:01,  4.86it/s]\n",
      "6it [00:01,  3.43it/s]\n",
      "7it [00:01,  3.87it/s]\n",
      "8it [00:01,  4.06it/s]\n",
      "9it [00:02,  4.25it/s]\n",
      "10it [00:02,  4.49it/s]\n",
      "11it [00:02,  4.61it/s]\n",
      "12it [00:02,  4.67it/s]\n",
      "13it [00:02,  4.68it/s]\n",
      "14it [00:03,  4.59it/s]\n",
      "15it [00:03,  4.72it/s]\n",
      "16it [00:03,  3.77it/s]\n",
      "17it [00:03,  4.12it/s]\n",
      "18it [00:04,  4.36it/s]\n",
      "19it [00:04,  4.37it/s]\n",
      "20it [00:04,  4.19it/s]\n",
      "21it [00:04,  4.14it/s]\n",
      "22it [00:05,  4.33it/s]\n",
      "23it [00:05,  4.31it/s]\n",
      "24it [00:05,  4.42it/s]\n",
      "25it [00:05,  4.69it/s]\n",
      "26it [00:05,  4.72it/s]\n",
      "27it [00:06,  4.69it/s]\n",
      "28it [00:06,  4.55it/s]\n",
      "29it [00:06,  4.70it/s]\n",
      "30it [00:06,  4.75it/s]\n",
      "31it [00:07,  4.70it/s]\n",
      "32it [00:07,  4.71it/s]\n",
      "33it [00:07,  4.53it/s]\n",
      "34it [00:07,  4.55it/s]\n",
      "35it [00:07,  4.49it/s]\n",
      "36it [00:08,  4.36it/s]\n",
      "37it [00:08,  4.45it/s]\n",
      "38it [00:08,  4.40it/s]\n",
      "39it [00:08,  4.44it/s]\n",
      "40it [00:09,  4.58it/s]\n",
      "41it [00:09,  4.62it/s]\n",
      "42it [00:09,  4.75it/s]\n",
      "43it [00:09,  4.87it/s]\n",
      "44it [00:09,  4.92it/s]\n",
      "45it [00:10,  4.98it/s]\n",
      "46it [00:10,  4.88it/s]\n",
      "47it [00:10,  4.80it/s]\n",
      "48it [00:10,  4.79it/s]\n",
      "49it [00:10,  4.77it/s]\n",
      "50it [00:11,  4.94it/s]\n",
      "51it [00:11,  4.92it/s]\n",
      "52it [00:11,  4.74it/s]\n",
      "53it [00:11,  4.72it/s]\n",
      "54it [00:11,  4.47it/s]\n",
      "55it [00:12,  4.47it/s]\n",
      "56it [00:12,  4.50it/s]\n",
      "57it [00:12,  4.37it/s]\n",
      "58it [00:12,  4.56it/s]\n",
      "59it [00:13,  4.49it/s]\n",
      "60it [00:13,  4.53it/s]\n",
      "61it [00:13,  4.67it/s]\n",
      "62it [00:13,  4.60it/s]\n",
      "63it [00:13,  4.55it/s]\n",
      "64it [00:14,  4.78it/s]\n",
      "65it [00:14,  4.97it/s]\n",
      "66it [00:14,  4.81it/s]\n",
      "67it [00:14,  4.74it/s]\n",
      "68it [00:14,  4.83it/s]\n",
      "69it [00:15,  4.70it/s]\n",
      "70it [00:15,  4.68it/s]\n",
      "71it [00:15,  4.67it/s]\n",
      "72it [00:15,  4.65it/s]\n",
      "73it [00:16,  4.32it/s]\n",
      "74it [00:16,  4.35it/s]\n",
      "75it [00:16,  4.42it/s]\n",
      "76it [00:16,  4.54it/s]\n",
      "77it [00:16,  4.55it/s]\n",
      "78it [00:17,  4.48it/s]\n",
      "79it [00:17,  4.41it/s]\n",
      "80it [00:17,  4.51it/s]\n",
      "81it [00:17,  4.41it/s]\n",
      "82it [00:18,  4.51it/s]\n",
      "83it [00:18,  4.63it/s]\n",
      "84it [00:18,  4.66it/s]\n",
      "85it [00:18,  4.70it/s]\n",
      "86it [00:18,  4.79it/s]\n",
      "87it [00:19,  4.83it/s]\n",
      "88it [00:19,  4.96it/s]\n",
      "89it [00:19,  4.77it/s]\n",
      "90it [00:19,  4.70it/s]\n",
      "91it [00:19,  4.88it/s]\n",
      "92it [00:20,  4.76it/s]\n",
      "93it [00:20,  4.60it/s]\n",
      "94it [00:20,  4.60it/s]\n",
      "95it [00:20,  4.66it/s]\n",
      "96it [00:21,  4.50it/s]\n",
      "97it [00:21,  4.58it/s]\n",
      "98it [00:21,  4.59it/s]\n",
      "99it [00:21,  4.75it/s]\n",
      "100it [00:21,  4.78it/s]\n",
      "101it [00:22,  4.57it/s]\n",
      "102it [00:22,  4.80it/s]\n",
      "103it [00:22,  4.78it/s]\n",
      "104it [00:22,  4.68it/s]\n",
      "105it [00:22,  4.80it/s]\n",
      "106it [00:23,  4.97it/s]\n",
      "108it [00:23,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<e : 2>> <<train_loss :  0.01>> <<train_accuracy : 57.00>> <<val_loss :  0.68>> <<val_accuracy : 57.00>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:48<07:11, 23.99s/it]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  4.18it/s]\n",
      "2it [00:00,  4.40it/s]\n",
      "3it [00:00,  4.58it/s]\n",
      "4it [00:00,  4.75it/s]\n",
      "5it [00:01,  4.87it/s]\n",
      "6it [00:01,  4.85it/s]\n",
      "7it [00:01,  4.93it/s]\n",
      "8it [00:01,  4.95it/s]\n",
      "9it [00:01,  4.83it/s]\n",
      "10it [00:02,  3.95it/s]\n",
      "11it [00:02,  3.61it/s]\n",
      "12it [00:02,  3.77it/s]\n",
      "13it [00:03,  3.86it/s]\n",
      "14it [00:03,  3.11it/s]\n",
      "15it [00:03,  3.40it/s]\n",
      "16it [00:03,  3.79it/s]\n",
      "17it [00:04,  4.12it/s]\n",
      "18it [00:04,  4.51it/s]\n",
      "19it [00:04,  4.70it/s]\n",
      "20it [00:04,  4.60it/s]\n",
      "21it [00:04,  4.81it/s]\n",
      "22it [00:05,  4.78it/s]\n",
      "23it [00:05,  4.74it/s]\n",
      "24it [00:05,  4.77it/s]\n",
      "25it [00:05,  4.76it/s]\n",
      "26it [00:05,  4.86it/s]\n",
      "27it [00:06,  5.09it/s]\n",
      "28it [00:06,  4.91it/s]\n",
      "29it [00:06,  4.85it/s]\n",
      "30it [00:06,  4.78it/s]\n",
      "31it [00:06,  4.55it/s]\n",
      "32it [00:07,  4.47it/s]\n",
      "33it [00:07,  4.62it/s]\n",
      "34it [00:07,  4.75it/s]\n",
      "35it [00:07,  4.61it/s]\n",
      "36it [00:08,  4.56it/s]\n",
      "37it [00:08,  4.75it/s]\n",
      "38it [00:08,  4.85it/s]\n",
      "39it [00:08,  4.98it/s]\n",
      "40it [00:08,  4.76it/s]\n",
      "41it [00:09,  4.95it/s]\n",
      "42it [00:09,  4.97it/s]\n",
      "43it [00:09,  5.06it/s]\n",
      "44it [00:09,  5.19it/s]\n",
      "45it [00:09,  4.98it/s]\n",
      "46it [00:10,  4.90it/s]\n",
      "47it [00:10,  4.96it/s]\n",
      "48it [00:10,  4.90it/s]\n",
      "49it [00:10,  4.74it/s]\n",
      "50it [00:10,  4.79it/s]\n",
      "51it [00:11,  4.62it/s]\n",
      "52it [00:11,  4.71it/s]\n",
      "53it [00:11,  4.68it/s]\n",
      "54it [00:11,  4.77it/s]\n",
      "55it [00:11,  4.75it/s]\n",
      "56it [00:12,  4.79it/s]\n",
      "57it [00:12,  4.80it/s]\n",
      "58it [00:12,  4.80it/s]\n",
      "59it [00:12,  4.88it/s]\n",
      "60it [00:13,  4.77it/s]\n",
      "61it [00:13,  4.65it/s]\n",
      "62it [00:13,  4.83it/s]\n",
      "63it [00:13,  4.97it/s]\n",
      "64it [00:13,  4.80it/s]\n",
      "65it [00:14,  4.91it/s]\n",
      "66it [00:14,  4.77it/s]\n",
      "67it [00:14,  4.86it/s]\n",
      "68it [00:14,  4.85it/s]\n",
      "69it [00:14,  5.01it/s]\n",
      "70it [00:15,  4.98it/s]\n",
      "71it [00:15,  4.81it/s]\n",
      "72it [00:15,  4.71it/s]\n",
      "73it [00:15,  4.75it/s]\n",
      "74it [00:15,  4.43it/s]\n",
      "75it [00:16,  4.46it/s]\n",
      "76it [00:16,  4.63it/s]\n",
      "77it [00:16,  4.53it/s]\n",
      "78it [00:16,  4.74it/s]\n",
      "79it [00:16,  4.86it/s]\n",
      "80it [00:17,  4.98it/s]\n",
      "81it [00:17,  4.88it/s]\n",
      "82it [00:17,  5.02it/s]\n",
      "83it [00:17,  4.80it/s]\n",
      "84it [00:18,  4.72it/s]\n",
      "85it [00:18,  4.64it/s]\n",
      "86it [00:18,  4.71it/s]\n",
      "87it [00:18,  4.89it/s]\n",
      "88it [00:18,  5.00it/s]\n",
      "89it [00:19,  5.28it/s]\n",
      "90it [00:19,  5.14it/s]\n",
      "91it [00:19,  5.10it/s]\n",
      "92it [00:19,  4.60it/s]\n",
      "93it [00:19,  4.62it/s]\n",
      "94it [00:20,  4.52it/s]\n",
      "95it [00:20,  4.66it/s]\n",
      "96it [00:20,  4.70it/s]\n",
      "97it [00:20,  4.52it/s]\n",
      "98it [00:21,  4.43it/s]\n",
      "99it [00:21,  4.69it/s]\n",
      "100it [00:21,  4.53it/s]\n",
      "101it [00:21,  4.58it/s]\n",
      "102it [00:21,  4.57it/s]\n",
      "103it [00:22,  4.44it/s]\n",
      "104it [00:22,  4.64it/s]\n",
      "105it [00:22,  4.75it/s]\n",
      "106it [00:22,  4.81it/s]\n",
      "107it [00:22,  4.89it/s]\n",
      "108it [00:23,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<e : 3>> <<train_loss :  0.01>> <<train_accuracy : 61.00>> <<val_loss :  0.58>> <<val_accuracy : 73.00>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [01:11<06:46, 23.92s/it]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  4.30it/s]\n",
      "2it [00:00,  4.12it/s]\n",
      "3it [00:00,  4.29it/s]\n",
      "4it [00:00,  4.30it/s]\n",
      "5it [00:01,  4.50it/s]\n",
      "6it [00:01,  4.62it/s]\n",
      "7it [00:01,  4.78it/s]\n",
      "8it [00:01,  4.97it/s]\n",
      "9it [00:01,  4.82it/s]\n",
      "10it [00:02,  4.78it/s]\n",
      "11it [00:02,  4.60it/s]\n",
      "12it [00:02,  4.33it/s]\n",
      "13it [00:02,  4.30it/s]\n",
      "14it [00:03,  4.55it/s]\n",
      "15it [00:03,  4.68it/s]\n",
      "16it [00:03,  4.71it/s]\n",
      "17it [00:03,  4.74it/s]\n",
      "18it [00:03,  4.65it/s]\n",
      "19it [00:04,  4.78it/s]\n",
      "20it [00:04,  4.80it/s]\n",
      "21it [00:04,  4.50it/s]\n",
      "22it [00:04,  4.63it/s]\n",
      "23it [00:04,  4.76it/s]\n",
      "24it [00:05,  4.85it/s]\n",
      "25it [00:05,  4.81it/s]\n",
      "26it [00:05,  4.70it/s]\n",
      "27it [00:05,  4.47it/s]\n",
      "28it [00:06,  4.68it/s]\n",
      "29it [00:06,  4.74it/s]\n",
      "30it [00:06,  4.83it/s]\n",
      "31it [00:06,  4.49it/s]\n",
      "32it [00:06,  4.51it/s]\n",
      "33it [00:07,  4.59it/s]\n",
      "34it [00:07,  4.58it/s]\n",
      "35it [00:07,  4.37it/s]\n",
      "36it [00:07,  4.30it/s]\n",
      "37it [00:08,  4.31it/s]\n",
      "38it [00:08,  4.57it/s]\n",
      "39it [00:08,  4.67it/s]\n",
      "40it [00:08,  4.40it/s]\n",
      "41it [00:08,  4.38it/s]\n",
      "42it [00:09,  4.45it/s]\n",
      "43it [00:09,  4.31it/s]\n",
      "44it [00:09,  4.62it/s]\n",
      "45it [00:09,  4.84it/s]\n",
      "46it [00:09,  4.94it/s]\n",
      "47it [00:10,  5.03it/s]\n",
      "48it [00:10,  4.97it/s]\n",
      "49it [00:10,  4.88it/s]\n",
      "50it [00:10,  4.91it/s]\n",
      "51it [00:10,  4.98it/s]\n",
      "52it [00:11,  4.89it/s]\n",
      "53it [00:11,  4.93it/s]\n",
      "54it [00:11,  4.80it/s]\n",
      "55it [00:11,  4.73it/s]\n",
      "56it [00:12,  4.59it/s]\n",
      "57it [00:12,  4.55it/s]\n",
      "58it [00:12,  4.34it/s]\n",
      "59it [00:12,  4.52it/s]\n",
      "60it [00:12,  4.63it/s]\n",
      "61it [00:13,  4.76it/s]\n",
      "62it [00:13,  4.75it/s]\n",
      "63it [00:13,  4.62it/s]\n",
      "64it [00:13,  4.76it/s]\n",
      "65it [00:13,  5.00it/s]\n",
      "66it [00:14,  4.65it/s]\n",
      "67it [00:14,  4.79it/s]\n",
      "68it [00:14,  4.99it/s]\n",
      "69it [00:14,  4.97it/s]\n",
      "70it [00:15,  4.73it/s]\n",
      "71it [00:15,  4.72it/s]\n",
      "72it [00:15,  4.49it/s]\n",
      "73it [00:15,  4.40it/s]\n",
      "74it [00:15,  4.52it/s]\n",
      "75it [00:16,  4.47it/s]\n",
      "76it [00:16,  4.74it/s]\n",
      "77it [00:16,  4.76it/s]\n",
      "78it [00:16,  4.90it/s]\n",
      "79it [00:16,  4.84it/s]\n",
      "80it [00:17,  4.93it/s]\n",
      "81it [00:17,  4.73it/s]\n",
      "82it [00:17,  4.76it/s]\n",
      "83it [00:17,  4.85it/s]\n",
      "84it [00:17,  4.92it/s]\n",
      "85it [00:18,  4.89it/s]\n",
      "86it [00:18,  4.38it/s]\n",
      "87it [00:18,  4.17it/s]\n",
      "88it [00:18,  4.22it/s]\n",
      "89it [00:19,  4.41it/s]\n",
      "90it [00:19,  4.28it/s]\n",
      "91it [00:19,  4.37it/s]\n",
      "92it [00:19,  4.61it/s]\n",
      "93it [00:20,  4.85it/s]\n",
      "94it [00:20,  5.00it/s]\n",
      "95it [00:20,  4.81it/s]\n",
      "96it [00:20,  4.69it/s]\n",
      "97it [00:20,  4.58it/s]\n",
      "98it [00:21,  4.67it/s]\n",
      "99it [00:21,  4.83it/s]\n",
      "100it [00:21,  4.89it/s]\n",
      "101it [00:21,  4.96it/s]\n",
      "102it [00:21,  4.83it/s]\n",
      "103it [00:22,  4.85it/s]\n",
      "104it [00:22,  4.90it/s]\n",
      "105it [00:22,  4.87it/s]\n",
      "106it [00:22,  5.02it/s]\n",
      "108it [00:22,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<e : 4>> <<train_loss :  0.01>> <<train_accuracy : 76.00>> <<val_loss :  0.56>> <<val_accuracy : 74.00>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:35<06:21, 23.85s/it]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  5.04it/s]\n",
      "2it [00:00,  5.12it/s]\n",
      "3it [00:00,  4.91it/s]\n",
      "4it [00:00,  5.02it/s]\n",
      "5it [00:00,  5.24it/s]\n",
      "6it [00:01,  5.20it/s]\n",
      "7it [00:01,  5.13it/s]\n",
      "8it [00:01,  4.94it/s]\n",
      "9it [00:01,  4.83it/s]\n",
      "10it [00:02,  4.82it/s]\n",
      "11it [00:02,  4.58it/s]\n",
      "12it [00:02,  4.77it/s]\n",
      "13it [00:02,  4.64it/s]\n",
      "14it [00:02,  4.57it/s]\n",
      "15it [00:03,  4.73it/s]\n",
      "16it [00:03,  4.67it/s]\n",
      "17it [00:03,  4.79it/s]\n",
      "18it [00:03,  4.55it/s]\n",
      "19it [00:03,  4.61it/s]\n",
      "20it [00:04,  4.61it/s]\n",
      "21it [00:04,  4.82it/s]\n",
      "22it [00:04,  5.02it/s]\n",
      "23it [00:04,  4.95it/s]\n",
      "24it [00:04,  4.90it/s]\n",
      "25it [00:05,  4.93it/s]\n",
      "26it [00:05,  4.83it/s]\n",
      "27it [00:05,  4.86it/s]\n",
      "28it [00:05,  4.96it/s]\n",
      "29it [00:05,  5.04it/s]\n",
      "30it [00:06,  4.95it/s]\n",
      "31it [00:06,  4.98it/s]\n",
      "32it [00:06,  4.83it/s]\n",
      "33it [00:06,  4.68it/s]\n",
      "34it [00:07,  4.51it/s]\n",
      "35it [00:07,  4.58it/s]\n",
      "36it [00:07,  4.61it/s]\n",
      "37it [00:07,  4.65it/s]\n",
      "38it [00:07,  4.66it/s]\n",
      "39it [00:08,  4.60it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-49900ba2a6c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-53b3953b7feb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_iter)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 기울기 0으로 초기화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-e05e4ae930b1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mh_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#첫 번째 은닉 벡터 정의\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# h_0 = [1, 64, 256]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# x = [64, 27, 256]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mh_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 526\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in tqdm(range(1, epochs + 1)):\n",
    "    train_loss, train_accuracy = train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"<<e : %d>> <<train_loss : %5.2f>> <<train_accuracy : %5.2f>> <<val_loss : %5.2f>> <<val_accuracy : %5.2f>>\"%(e, train_loss, train_accuracy, val_loss, val_accuracy))\n",
    "    sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
